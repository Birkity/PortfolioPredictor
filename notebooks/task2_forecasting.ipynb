{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import mlflow\n",
    "\n",
    "sys.path.append(os.path.abspath('../scripts'))\n",
    "\n",
    "from forecasting.arima_model import train_arima\n",
    "from forecasting.sarima_model import train_sarima\n",
    "from forecasting.lstm_model import preprocess_data, build_lstm, train_lstm\n",
    "from forecasting.evaluation_metrics import evaluate_forecast\n",
    "from utils.mlflow_utils import (\n",
    "    start_mlflow_experiment, log_params, log_metrics, log_model, end_mlflow_experiment\n",
    ")\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 15:24:08,152 - INFO - Logger initialized. Log file: logs\\task2_mlflow_forecasting.log\n"
     ]
    }
   ],
   "source": [
    "from utils.logging_config import setup_logger\n",
    "setup_logger(log_file=\"task2_mlflow_forecasting.log\", log_level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 15:24:08,270 - INFO - Task 2: Forecasting Pipeline with Multiple Datasets Started.\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Task 2: Forecasting Pipeline with Multiple Datasets Started.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"TSLA\": pd.read_csv(\"../data/processed/TSLA_processed.csv\", parse_dates=[\"Date\"], index_col=\"Date\"),\n",
    "    \"SPY\": pd.read_csv(\"../data/processed/SPY_processed.csv\", parse_dates=[\"Date\"], index_col=\"Date\"),\n",
    "    \"BND\": pd.read_csv(\"../data/processed/BND_processed.csv\", parse_dates=[\"Date\"], index_col=\"Date\"),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 15:27:16,094 - INFO - Processing dataset: TSLA\n",
      "2024-11-17 15:27:16,344 - INFO - Training ARIMA for TSLA with order (0, 1, 1)...\n",
      "2024-11-17 15:27:16,345 - INFO - Starting ARIMA training with order (0, 1, 1).\n",
      "2024-11-17 15:27:16,400 - INFO - ARIMA training completed with order (0, 1, 1).\n",
      "2024/11/17 15:27:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024-11-17 15:27:20,411 - INFO - Logged model: arima_model_TSLA to MLflow.\n",
      "2024-11-17 15:27:20,419 - INFO - Completed processing for TSLA. Metrics: {'MAE': np.float64(178.48832758615592), 'RMSE': np.float64(202.56084136042602)}\n",
      "2024-11-17 15:27:20,423 - INFO - Processing dataset: SPY\n",
      "2024-11-17 15:27:20,573 - INFO - Training ARIMA for SPY with order (3, 1, 1)...\n",
      "2024-11-17 15:27:20,573 - INFO - Starting ARIMA training with order (3, 1, 1).\n",
      "2024-11-17 15:27:20,873 - INFO - ARIMA training completed with order (3, 1, 1).\n",
      "2024/11/17 15:27:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024-11-17 15:27:24,309 - INFO - Logged model: arima_model_SPY to MLflow.\n",
      "2024-11-17 15:27:24,310 - INFO - Completed processing for SPY. Metrics: {'MAE': np.float64(75.55185254199635), 'RMSE': np.float64(87.56082771996167)}\n",
      "2024-11-17 15:27:24,314 - INFO - Processing dataset: BND\n",
      "2024-11-17 15:27:24,411 - INFO - Training ARIMA for BND with order (0, 1, 0)...\n",
      "2024-11-17 15:27:24,411 - INFO - Starting ARIMA training with order (0, 1, 0).\n",
      "2024-11-17 15:27:24,474 - INFO - ARIMA training completed with order (0, 1, 0).\n",
      "2024/11/17 15:27:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024-11-17 15:27:27,809 - INFO - Logged model: arima_model_BND to MLflow.\n",
      "2024-11-17 15:27:27,809 - INFO - Completed processing for BND. Metrics: {'MAE': np.float64(4.004515148344494), 'RMSE': np.float64(4.31833703878107)}\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, data in datasets.items():\n",
    "    logging.info(f\"Processing dataset: {name}\")\n",
    "\n",
    "    train = data['Adj Close'][:'2019']\n",
    "    test = data['Adj Close']['2020':]\n",
    "\n",
    "    arima_orders = {\n",
    "        \"TSLA\": (0, 1, 1),\n",
    "        \"SPY\": (3, 1, 1),\n",
    "        \"BND\": (0, 1, 0)\n",
    "    }\n",
    "\n",
    "    with mlflow.start_run(nested=True, run_name=f\"ARIMA_{name}\"):\n",
    "        logging.info(f\"Training ARIMA for {name} with order {arima_orders[name]}...\")\n",
    "        \n",
    "        arima_model = train_arima(train, order=arima_orders[name])\n",
    "        \n",
    "        arima_forecast = arima_model.forecast(steps=len(test))\n",
    "        \n",
    "        arima_metrics = evaluate_forecast(test.values, arima_forecast)\n",
    "        \n",
    "        log_params({\"dataset\": name, \"model\": \"ARIMA\", \"order\": arima_orders[name]})\n",
    "        log_metrics(arima_metrics)\n",
    "        log_model(arima_model, f\"arima_model_{name}\")\n",
    "\n",
    "        results[name] = {\"test\": test, \"arima_forecast\": arima_forecast}\n",
    "\n",
    "        logging.info(f\"Completed processing for {name}. Metrics: {arima_metrics}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
